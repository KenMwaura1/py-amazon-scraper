name: Python package

on:
  push:
    branches: [ "dev","main" ]
  pull_request:
    branches: [ "dev","main" ]

jobs:
  db_setup:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:latest
        env:
          PG_USER: test
          PG_PASSWORD: testpassword
          PG_DB: amazon_data
        ports: ['5432:5432']
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
    steps:
      - name: PostgreSQL Check
        run: |
          psql -h localhost -U test -d amazon_data -c "SELECT version();"
      - name: Setup PostgreSQL 13.1
        uses: Harmon758/postgresql-action@v1.0.0
        with:
            # Version of PostgreSQL to use
            postgresql version: 13.1-alpine
            # POSTGRES_DB - name for the default database that is created
            postgresql db: amazon_data
            # POSTGRES_USER - create the specified user with superuser power
            postgresql user: test
            # POSTGRES_PASSWORD - superuser password
            postgresql password: testpassword
  build:
    needs: [db_setup]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, "3.10"]

    steps:
      - uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
            python -m pip install --upgrade pip
            pip install -r requirements.txt
      - name: Lint with flake8
        run: |
            pip install flake8
            # stop the build if there are Python syntax errors or undefined names
            flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
            # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
            flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      - name: app-test
        run: |
          cd amz_scraper
          scrapy crawl amznspider 
  